{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "region = boto3.Session().region_name  # must be in the same region as the S3 data!\n",
    "bucket = \"sagemaker-bitty-magazines\"  # pipeline steps use S3 storage extensively\n",
    "model_package_group_name = f\"BittiModelPackageGroupName\"  # enables model versioning\n",
    "prefix = 'sagemaker_pipelines_bitti'\n",
    "turicreate_logs_path = \"s3://{}/{}/logs\".format(bucket, prefix)\n",
    "\n",
    "print('Bucket: {}'.format(bucket))\n",
    "print('Execution role: {}'.format(role))\n",
    "print('SageMaker ver: ' + sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing step\n",
    "\n",
    "Download the dataset, convert it into Turi Create's `SFrame` object, and save the output on S3 in a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining some variables\n",
    "\n",
    "s3_input = f\"s3://{bucket}/bitti-data-yolo-format/\"\n",
    "source_dir = \"pipelines/bitti\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"30d\")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1)\n",
    "\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.t3.large\")  # ml.t3.medium runs out of RAM on eval stage\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.c5.9xlarge\")  # TODO: get the GPU tested and running\n",
    "\n",
    "training_batch_size = ParameterInteger(\n",
    "    name=\"TrainingBatchSize\",\n",
    "    default_value=32)\n",
    "\n",
    "training_max_iterations = ParameterInteger(\n",
    "    name=\"MaxIterations\",\n",
    "    default_value=300)\n",
    "\n",
    "training_n_cores = ParameterInteger(\n",
    "    name=\"NumPyLambdaWorkers\",\n",
    "    default_value=36)\n",
    "\n",
    "# this will also be used for preprocessing - TC runs on TF now\n",
    "training_instance_tf_version = ParameterString(\n",
    "    name=\"TrainingInstanceTFVersion\",\n",
    "    default_value=\"2.3\")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    #default_value=\"PendingManualApproval\")\n",
    "    default_value=\"Approved\")\n",
    "\n",
    "model_approval_map_threshold = ParameterFloat(\n",
    "    name=\"ModelApprovalmAPThreshold\",\n",
    "    default_value=0.7)\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=s3_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "\n",
    "preprocessing_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    image_scope=\"inference\",\n",
    "    region=region,\n",
    "    version=str(training_instance_tf_version),\n",
    "    py_version=\"py37\",\n",
    "    instance_type=processing_instance_type)\n",
    "\n",
    "sframes_preproessor = ScriptProcessor(\n",
    "    image_uri=preprocessing_image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    env={\"TrainSplitFraction\": \"0.9\"},  # TODO: make it a pipeline param\n",
    "    base_job_name=\"script-sframe-conversion\",\n",
    "    role=role)\n",
    "\n",
    "step_sframe_process = ProcessingStep(\n",
    "    name=\"BittiDataProcessing\",\n",
    "    processor=sframes_preproessor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/output_train\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/output_test\")\n",
    "    ],\n",
    "    code=f\"{source_dir}/preprocessing.py\",\n",
    "    cache_config=cache_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for the main bit - the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "model_path = f\"s3://{bucket}/output_model\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    image_scope=\"training\",\n",
    "    region=region,\n",
    "    version=str(training_instance_tf_version),\n",
    "    py_version=\"py37\",\n",
    "    instance_type=training_instance_type)\n",
    "\n",
    "# Regular expressions are a pain, use the playground here: https://regex101.com/r/kopij0/1\n",
    "# TODO: works for reporting, but how to publish it via CloudWatch metrics as well?\n",
    "turicreate_metrics = [{'Name': 'train:loss', 'Regex': r\"(?:\\| [0-9]+ \\| )([0-9]+[.][0-9]+)\"}]\n",
    "\n",
    "tf_train = TensorFlow(base_job_name='bitti-turicreate-pipelines',\n",
    "                      entry_point='training.py',\n",
    "                      source_dir=source_dir,\n",
    "                      output_path=model_path,  # don't use model_dir hyperparam!\n",
    "                      role=role,\n",
    "                      image_uri=image_uri,\n",
    "                      hyperparameters={'max-iterations': int(training_max_iterations),\n",
    "                                       'batch-size': int(training_batch_size),\n",
    "                                       'number-pylambda-workers': int(training_n_cores)\n",
    "                                      },\n",
    "                      instance_count=1,\n",
    "                      instance_type=str(training_instance_type),\n",
    "                      metric_definitions=turicreate_metrics,\n",
    "                      input_mode='File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "# TODO: change into Pipe - but that would need additional read f-ions in training.py\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"ModelTraining\",\n",
    "    estimator=tf_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(step_sframe_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "                               #content_type=\"application/octet-stream\",  # Tested, not needed for File mode\n",
    "                               input_mode=\"File\"),\n",
    "        \"test\": TrainingInput(step_sframe_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "                              #content_type=\"application/octet-stream\",\n",
    "                              input_mode=\"File\")},\n",
    "    cache_config=cache_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the evaluation step\n",
    "\n",
    "We have trained the model, but we need to validate it too. What happened the first time was, due to the EXIF tags half of images were not rotated properly relative to the labels. Needless to say, that led to the mAP score to be close to nill. That's a good example for why the validation step is needed - only models that *work* should be carried on with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-bitti-eval\",\n",
    "    role=role)\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"ModelEvaluation\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"),\n",
    "        ProcessingInput(\n",
    "            source=step_sframe_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\")],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\")],\n",
    "    code=f\"{source_dir}/evaluation.py\",\n",
    "    property_files=[evaluation_report])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep, JsonGet\n",
    "\n",
    "\n",
    "cond_map = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mAP.value\"),\n",
    "    right=model_approval_map_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "step_register = RegisterModel(\n",
    "    name=\"BittiRegisterModel\",\n",
    "    estimator=tf_train,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/octet-stream\"],\n",
    "    response_types=[\"application/octet-stream\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_publish = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-bitti-publish\",\n",
    "    role=role)\n",
    "\n",
    "step_publish = ProcessingStep(\n",
    "    name=\"PublishViaAPI\",\n",
    "    processor=script_publish,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\")],\n",
    "    code=f\"{source_dir}/publish_to_api.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_cond = ConditionStep(\n",
    "    name=\"BittymAPcheck\",\n",
    "    conditions=[cond_map],\n",
    "    if_steps=[step_register, step_publish],\n",
    "    else_steps=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline_name = \"BittiPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        training_instance_type,\n",
    "        training_batch_size,\n",
    "        training_max_iterations,\n",
    "        training_n_cores,\n",
    "        training_instance_tf_version,\n",
    "        model_approval_status,\n",
    "        input_data,\n",
    "        model_approval_map_threshold\n",
    "    ],\n",
    "    steps=[step_sframe_process, step_train, step_eval, step_cond],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.describe()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
